{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1wEM7sZrPrj"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets accelerate evaluate"
      ],
      "metadata": {
        "id": "6QCDdg-PsASi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer,pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import torch, os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "aFDslxfGsAVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "W84rCB2PsAXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_org = pd.read_csv(\"train.csv\")\n",
        "df_org.rename(columns={'labels': 'category','tweets':'text'},inplace=True)\n",
        "df_org.head(10)"
      ],
      "metadata": {
        "id": "Uwjv9WeKsAZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df_org['category'].unique().tolist()\n",
        "labels = [s.strip() for s in labels ]\n",
        "labels"
      ],
      "metadata": {
        "id": "TFaXDnbdsAcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in enumerate(labels):\n",
        "    print(value)"
      ],
      "metadata": {
        "id": "a9cIMCyesAga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_LABELS= len(labels)\n",
        "\n",
        "id2label={id:label for id,label in enumerate(labels)}\n",
        "\n",
        "label2id={label:id for id,label in enumerate(labels)}"
      ],
      "metadata": {
        "id": "v-BMNFppsAi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_org[\"labels\"]=df_org.category.map(lambda x: label2id[x.strip()])\n",
        "df_org.head(5)"
      ],
      "metadata": {
        "id": "LxFVYzc3sAlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'finiteautomata/bertweet-base-emotion-analysis'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_path,\n",
        "    num_labels=NUM_LABELS, id2label=id2label, label2id=label2id,\n",
        "    ignore_mismatched_sizes=True)\n",
        "\n",
        "model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, max_length=512)"
      ],
      "metadata": {
        "id": "4ojpkuFWsAnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE= df_org.shape[0]\n",
        "\n",
        "train_texts= list(df_org.text[:SIZE//2])\n",
        "\n",
        "val_texts=   list(df_org.text[SIZE//2:(3*SIZE)//4 ])\n",
        "\n",
        "test_texts=  list(df_org.text[(3*SIZE)//4:])\n",
        "\n",
        "train_labels= list(df_org.labels[:SIZE//2])\n",
        "\n",
        "val_labels=   list(df_org.labels[SIZE//2:(3*SIZE)//4])\n",
        "\n",
        "test_labels=  list(df_org.labels[(3*SIZE)//4:])"
      ],
      "metadata": {
        "id": "w_ghRhiNsAqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings  = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "QslAjvDtsAs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "b4_9hWQtsAvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_encodings, train_labels)\n",
        "\n",
        "val_dataloader = DataLoader(val_encodings, val_labels)\n",
        "\n",
        "test_dataset = DataLoader(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "5GzVQkVUsAxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'Accuracy': acc,\n",
        "        'F1': f1,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall\n",
        "    }\n"
      ],
      "metadata": {
        "id": "JWk_FsLysAzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/',\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy='steps',\n",
        "    logging_dir='./log',\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    fp16=True\n",
        ")"
      ],
      "metadata": {
        "id": "rKEuFMvytbYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataloader,\n",
        "    eval_dataset=val_dataloader,\n",
        "    compute_metrics= compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "nYF5pwORtbbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "p-hgA0Aetbdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q=[trainer.evaluate(eval_dataset=df_org) for df_org in [train_dataloader, val_dataloader, test_dataset]]\n",
        "\n",
        "pd.DataFrame(q, index=[\"train\",\"val\",\"test\"]).iloc[:,:5]"
      ],
      "metadata": {
        "id": "eR_2aItwtxXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "lX3pFYwnuG_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"mental-health-tweets-classification-model-1\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "id": "A4cimZ8NtxaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load the model"
      ],
      "metadata": {
        "id": "N2L_w9EuuJ2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"mental-health-tweets-classification-model-2\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"mental-health-tweets-classification-model-2\")\n",
        "nlp= pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "7gUZHAMbt_X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the some tweets"
      ],
      "metadata": {
        "id": "3RBAlkfpu2lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_org.head(5)\n",
        "stressed_example = df_org['text'][0]\n",
        "normal_example  = df_org['text'][2]\n",
        "lonely_example = df_org['text'][3]\n",
        "anxious_example = df_org['text'][1]\n",
        "df_org.head(5)"
      ],
      "metadata": {
        "id": "JTSyovWhuFe-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}